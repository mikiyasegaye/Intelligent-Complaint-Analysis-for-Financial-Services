{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Text Chunking and Embedding Generation\n",
        "\n",
        "This notebook implements Task 2 of the Financial Complaints Analysis project, which involves:\n",
        "1. Chunking the complaint narratives into smaller segments\n",
        "2. Generating embeddings using Sentence Transformers\n",
        "3. Storing the embeddings in a vector database (ChromaDB)\n",
        "\n",
        "## Setup and Imports\n",
        "The following cell sets up the environment and imports necessary libraries:\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Loading\n",
        "Loading the preprocessed complaints data from the CSV file. This data has already been cleaned in the previous notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Add project root to sys.path so config can be imported\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Set project root (assumes this notebook is in 'notebooks/')\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "from tqdm.notebook import tqdm\n",
        "import joblib\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# Import project-specific config\n",
        "from config.config import PROCESSED_DATA_DIR, VECTOR_STORE_DIR\n",
        "\n",
        "# Environment settings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Ensure vector store directory exists\n",
        "VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Text Chunking Function\n",
        "This function splits complaint texts into smaller chunks while preserving context:\n",
        "- Uses RecursiveCharacterTextSplitter for intelligent text splitting\n",
        "- Maintains chunk size of 500 characters with 50 character overlap\n",
        "- Preserves metadata for each chunk\n",
        "- Filters out chunks that are too short (< 50 characters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading complaint data...\n",
            "Loaded 443472 complaints\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>complaint_narrative</th>\n",
              "      <th>cleaned_narrative</th>\n",
              "      <th>product</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>issue</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>company</th>\n",
              "      <th>state</th>\n",
              "      <th>date_received</th>\n",
              "      <th>complaint_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A XXXX XXXX card was opened under my name by a...</td>\n",
              "      <td>a [REDACTED] [REDACTED] card was opened under ...</td>\n",
              "      <td>credit card</td>\n",
              "      <td>store credit card</td>\n",
              "      <td>getting a credit card</td>\n",
              "      <td>card opened without my consent or knowledge</td>\n",
              "      <td>citibank, n.a.</td>\n",
              "      <td>tx</td>\n",
              "      <td>2025-06-13</td>\n",
              "      <td>14069121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I made the mistake of using my wellsfargo debi...</td>\n",
              "      <td>i made the mistake of using my wellsfargo debi...</td>\n",
              "      <td>checking or savings account</td>\n",
              "      <td>checking account</td>\n",
              "      <td>managing an account</td>\n",
              "      <td>deposits and withdrawals</td>\n",
              "      <td>wells fargo &amp; company</td>\n",
              "      <td>id</td>\n",
              "      <td>2025-06-13</td>\n",
              "      <td>14061897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear CFPB, I have a secured credit card with c...</td>\n",
              "      <td>dear cfpb i have a secured credit card with ci...</td>\n",
              "      <td>credit card</td>\n",
              "      <td>general-purpose credit card or charge card</td>\n",
              "      <td>other features, terms, or problems</td>\n",
              "      <td>other problem</td>\n",
              "      <td>citibank, n.a.</td>\n",
              "      <td>ny</td>\n",
              "      <td>2025-06-12</td>\n",
              "      <td>14047085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a Citi rewards cards. The credit balanc...</td>\n",
              "      <td>i have a citi rewards cards the credit balance...</td>\n",
              "      <td>credit card</td>\n",
              "      <td>general-purpose credit card or charge card</td>\n",
              "      <td>incorrect information on your report</td>\n",
              "      <td>account information incorrect</td>\n",
              "      <td>citibank, n.a.</td>\n",
              "      <td>il</td>\n",
              "      <td>2025-06-12</td>\n",
              "      <td>14040217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'I am writing to dispute the following charge...</td>\n",
              "      <td>i am writing to dispute the following charges ...</td>\n",
              "      <td>credit card</td>\n",
              "      <td>general-purpose credit card or charge card</td>\n",
              "      <td>problem with a purchase shown on your statement</td>\n",
              "      <td>credit card company isn't resolving a dispute ...</td>\n",
              "      <td>citibank, n.a.</td>\n",
              "      <td>tx</td>\n",
              "      <td>2025-06-09</td>\n",
              "      <td>13968411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 complaint_narrative  \\\n",
              "0  A XXXX XXXX card was opened under my name by a...   \n",
              "1  I made the mistake of using my wellsfargo debi...   \n",
              "2  Dear CFPB, I have a secured credit card with c...   \n",
              "3  I have a Citi rewards cards. The credit balanc...   \n",
              "4  b'I am writing to dispute the following charge...   \n",
              "\n",
              "                                   cleaned_narrative  \\\n",
              "0  a [REDACTED] [REDACTED] card was opened under ...   \n",
              "1  i made the mistake of using my wellsfargo debi...   \n",
              "2  dear cfpb i have a secured credit card with ci...   \n",
              "3  i have a citi rewards cards the credit balance...   \n",
              "4  i am writing to dispute the following charges ...   \n",
              "\n",
              "                       product                                 sub_product  \\\n",
              "0                  credit card                           store credit card   \n",
              "1  checking or savings account                            checking account   \n",
              "2                  credit card  general-purpose credit card or charge card   \n",
              "3                  credit card  general-purpose credit card or charge card   \n",
              "4                  credit card  general-purpose credit card or charge card   \n",
              "\n",
              "                                             issue  \\\n",
              "0                            getting a credit card   \n",
              "1                              managing an account   \n",
              "2               other features, terms, or problems   \n",
              "3             incorrect information on your report   \n",
              "4  problem with a purchase shown on your statement   \n",
              "\n",
              "                                           sub_issue                company  \\\n",
              "0        card opened without my consent or knowledge         citibank, n.a.   \n",
              "1                           deposits and withdrawals  wells fargo & company   \n",
              "2                                      other problem         citibank, n.a.   \n",
              "3                      account information incorrect         citibank, n.a.   \n",
              "4  credit card company isn't resolving a dispute ...         citibank, n.a.   \n",
              "\n",
              "  state date_received  complaint_id  \n",
              "0    tx    2025-06-13      14069121  \n",
              "1    id    2025-06-13      14061897  \n",
              "2    ny    2025-06-12      14047085  \n",
              "3    il    2025-06-12      14040217  \n",
              "4    tx    2025-06-09      13968411  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Loading complaint data...\")\n",
        "df = pd.read_csv(PROCESSED_DATA_DIR / 'complaints_rag.csv')\n",
        "print(f\"Loaded {len(df)} complaints\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Embedding Generation\n",
        "Setting up the embedding model and generation function:\n",
        "- Uses all-MiniLM-L6-v2 model from Sentence Transformers\n",
        "- Leverages MPS acceleration on Apple Silicon\n",
        "- Implements efficient batch processing\n",
        "- Tracks progress and performance metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_complaint_chunks(complaint_text: str, metadata: Dict, chunk_size: int = 500, chunk_overlap: int = 50) -> List[Document]:\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "    )\n",
        "    texts = splitter.split_text(complaint_text)\n",
        "    texts = [text for text in texts if len(text.strip()) > 50]\n",
        "    return [\n",
        "        Document(page_content=text, metadata={**metadata, \"chunk_index\": i, \"total_chunks\": len(texts)})\n",
        "        for i, text in enumerate(texts)\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Caching Embeddings\n",
        "To avoid regenerating embeddings on every run:\n",
        "- Checks for cached embeddings in `cached_embeddings.pkl`\n",
        "- If not found, generates new embeddings\n",
        "- Saves embeddings to cache for future use\n",
        "\n",
        "Note: The cache file is large and should be added to .gitignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02fdf6c0c47441cfb2faccfcd7afe380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Chunking complaints:   0%|          | 0/443472 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks created: 1336041\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating chunks...\")\n",
        "chunk_size = 500\n",
        "chunk_overlap = 50\n",
        "all_documents = []\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Chunking complaints\"):\n",
        "    metadata = {\n",
        "        'complaint_id': str(row['complaint_id']),\n",
        "        'product': row['product'],\n",
        "        'sub_product': row['sub_product'],\n",
        "        'company': row['company'],\n",
        "        'state': row['state'],\n",
        "        'date_received': row['date_received']\n",
        "    }\n",
        "    chunks = create_complaint_chunks(row['cleaned_narrative'], metadata, chunk_size, chunk_overlap)\n",
        "    all_documents.extend(chunks)\n",
        "\n",
        "print(f\"Total chunks created: {len(all_documents)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Vector Store Setup\n",
        "Setting up ChromaDB as our vector store:\n",
        "- Creates a persistent collection\n",
        "- Stores embeddings on disk for future use\n",
        "- Maintains all metadata for each chunk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'all-MiniLM-L6-v2'\n",
        "embedding_model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "def generate_embeddings(documents: List[Document], batch_size: int = 64) -> Tuple[List[str], List[Dict], List[np.ndarray]]:\n",
        "    ids = [f\"chunk_{doc.metadata['complaint_id']}_{doc.metadata['chunk_index']}\" for doc in documents]\n",
        "    texts = [doc.page_content for doc in documents]\n",
        "    metadatas = [doc.metadata for doc in documents]\n",
        "\n",
        "    embeddings = []\n",
        "    total_time = 0\n",
        "    n_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), total=n_batches, desc=\"Generating embeddings\"):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        start = time.time()\n",
        "        batch_embeddings = embedding_model.encode(\n",
        "            batch_texts, convert_to_numpy=True, show_progress_bar=False, batch_size=batch_size\n",
        "        )\n",
        "        embeddings.extend(batch_embeddings)\n",
        "        total_time += time.time() - start\n",
        "\n",
        "    print(f\"Total time: {total_time:.2f}s | Avg speed: {len(texts)/total_time:.1f} docs/s\")\n",
        "    return ids, metadatas, embeddings\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Test Query\n",
        "Testing the vector store with a sample query:\n",
        "- Generates embedding for the query text\n",
        "- Retrieves most similar documents\n",
        "- Shows relevant metadata and similarity scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98dcffe7c93a4b4faedec40fc57d3f15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/20876 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 2011.38s | Avg speed: 664.2 docs/s\n"
          ]
        }
      ],
      "source": [
        "cache_path = Path(\"../.cache/cached_embeddings.pkl\")\n",
        "\n",
        "if cache_path.exists():\n",
        "    print(\"Loading cached embeddings...\")\n",
        "    ids, metadatas, embeddings = joblib.load(cache_path)\n",
        "else:\n",
        "    ids, metadatas, embeddings = generate_embeddings(all_documents)\n",
        "    joblib.dump((ids, metadatas, embeddings), cache_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection created.\n"
          ]
        }
      ],
      "source": [
        "chroma_client = chromadb.Client(Settings(\n",
        "    persist_directory=str(VECTOR_STORE_DIR),\n",
        "    is_persistent=True\n",
        "))\n",
        "\n",
        "collection_name = \"financial_complaints\"\n",
        "try:\n",
        "    collection = chroma_client.get_collection(collection_name)\n",
        "    print(\"Collection loaded.\")\n",
        "except:\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=collection_name,\n",
        "        metadata={\"description\": \"Financial complaints embeddings\"}\n",
        "    )\n",
        "    print(\"Collection created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexing documents to ChromaDB in batches...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5863435f3a71438d8218649f60a9f490",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adding to ChromaDB:   0%|          | 0/1337 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Total documents in store: 1336041\n"
          ]
        }
      ],
      "source": [
        "print(\"Indexing documents to ChromaDB in batches...\")\n",
        "\n",
        "# Configure safe batch size under the 5461 limit\n",
        "batch_size = 1000\n",
        "\n",
        "for i in tqdm(range(0, len(ids), batch_size), desc=\"Adding to ChromaDB\"):\n",
        "    batch_ids = ids[i:i + batch_size]\n",
        "    batch_embeddings = embeddings[i:i + batch_size]\n",
        "    batch_metadatas = metadatas[i:i + batch_size]\n",
        "    batch_docs = [doc.page_content for doc in all_documents[i:i + batch_size]]\n",
        "    \n",
        "    collection.add(\n",
        "        ids=batch_ids,\n",
        "        embeddings=batch_embeddings,\n",
        "        metadatas=batch_metadatas,\n",
        "        documents=batch_docs\n",
        "    )\n",
        "\n",
        "print(f\"\\n✅ Total documents in store: {collection.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query Results:\n",
            "\n",
            "Result 1:\n",
            "Distance: 0.4562\n",
            "Product: credit card or prepaid card\n",
            "Company: ally financial inc.\n",
            "Text: i am making payments yet not getting to use my card...\n",
            "\n",
            "Result 2:\n",
            "Distance: 0.4648\n",
            "Product: credit card or prepaid card\n",
            "Company: avant holding company, inc.\n",
            "Text: saying my payment did not go through though there are funds in the account i tried to pay with i have other credit cards ive no problem paying but this one never seems to take my payments...\n"
          ]
        }
      ],
      "source": [
        "query_text = \"I have an issue with my credit card payment\"\n",
        "query_embedding = embedding_model.encode(query_text)\n",
        "\n",
        "results = collection.query(\n",
        "    query_embeddings=[query_embedding],\n",
        "    n_results=2,\n",
        "    include=['documents', 'metadatas', 'distances']\n",
        ")\n",
        "\n",
        "print(\"\\nQuery Results:\")\n",
        "for i, (doc, metadata, distance) in enumerate(zip(\n",
        "    results['documents'][0], results['metadatas'][0], results['distances'][0]\n",
        ")):\n",
        "    print(f\"\\nResult {i+1}:\")\n",
        "    print(f\"Distance: {distance:.4f}\")\n",
        "    print(f\"Product: {metadata['product']}\")\n",
        "    print(f\"Company: {metadata['company']}\")\n",
        "    print(f\"Text: {doc[:200]}...\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
